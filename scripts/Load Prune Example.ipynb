{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f340123-9870-4368-a787-8c74584b1e72",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "615b10bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shrinkbench.experiment import PruningExperiment, PruningClass\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1b00629",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['ShrinkPATH'] = './shrinkbench'\n",
    "os.environ['DATAPATH'] = './shrinkbench/Training_data'\n",
    "# ShrinkPATH is the path from the directory this file is located to the shrinkbench code\n",
    "# DATAPATH is the path from the current directory to where the datasets are located\n",
    "# The only think you might need to change is 'shrinkbench' to whatever the name of the file is that \n",
    "# contains the shrinkbench code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9924ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressions = [4, 10, 20, 30, 40, 50]\n",
    "strategies = [\"GlobalMagWeight\"]\n",
    "# These are the compression ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d6a0b3",
   "metadata": {},
   "source": [
    "This main block of code below should be rerun any time you switch between datasets and architectures. Otherwise does not need to be rerun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "805c5cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mGPU AVAILABLE\n",
      "\u001b[0m\u001b[92mGPU AVAILABLE\n",
      "\u001b[0m\u001b[95mLogging results to results/20220201-085854-0N2F-LeNet\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val -1/30: 100%|███████████████████████████████████| 79/79 [00:03<00:00, 23.37it/s, loss=0.0181, top1=0.101, top5=0.493]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight', Parameter containing:\n",
      "tensor([[[[ 0.1851,  0.2564,  0.1760],\n",
      "          [ 0.2751, -0.1985,  0.1324],\n",
      "          [-0.0854,  0.0140,  0.3030]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1977,  0.0573,  0.1206],\n",
      "          [ 0.1231,  0.2720,  0.0632],\n",
      "          [-0.0495,  0.3268,  0.2366]]],\n",
      "\n",
      "\n",
      "        [[[-0.2403,  0.1753,  0.1676],\n",
      "          [ 0.1516,  0.2574,  0.0985],\n",
      "          [ 0.3129,  0.2268,  0.2956]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0959, -0.0309,  0.2060],\n",
      "          [-0.1100,  0.2719, -0.1495],\n",
      "          [-0.0752,  0.1183, -0.0376]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2525, -0.0667, -0.0878],\n",
      "          [-0.2697,  0.2908, -0.0161],\n",
      "          [-0.2904,  0.0182, -0.1577]]],\n",
      "\n",
      "\n",
      "        [[[-0.1141,  0.1441, -0.1331],\n",
      "          [ 0.2654, -0.0195, -0.1564],\n",
      "          [ 0.0845, -0.2460, -0.2242]]]], device='cuda:0', requires_grad=True)), ('bias', Parameter containing:\n",
      "tensor([ 0.1616, -0.0417, -0.0440,  0.0650, -0.3126,  0.1025], device='cuda:0',\n",
      "       requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "# This is the overarching object that is interacted with. \n",
    "exp = PruningClass(dataset='QMNIST', # Change this to 'Fashion', 'CIFAR10', or 'CIFAR100' \n",
    "                model='LeNet',  # LeNetChange this to 'resnet56' for CIFAR10, or 'resnet56_C' for CIFAR100\n",
    "                train_kwargs={\n",
    "                    'optim': 'SGD',\n",
    "                    'epochs': 30,\n",
    "                    'lr': 1e-2},\n",
    "                dl_kwargs={'batch_size':128},\n",
    "                save_freq=1)\n",
    "exp.run_init()  # Sets up some stuff, can ignore output\n",
    "print(list(exp.model.conv1.named_parameters())) # List weights of first layer in LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede172b2",
   "metadata": {},
   "source": [
    "Load a trained model before prune/finetune.\n",
    "\n",
    "This is specific for qmnist, but the naming scheme is the same for the other models<br>\n",
    "example file: qmnist3.pt <br>\n",
    "'qmnist' is the dataset the model is for<br>\n",
    "'3' is the model number (0-9)<br>\n",
    "When passing the name to the load_model() function, do not include the .pt at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78dd9e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mGPU AVAILABLE\n",
      "\u001b[0m[('weight', Parameter containing:\n",
      "tensor([[[[-0.3878, -0.3219, -0.2951],\n",
      "          [ 0.1081,  0.0065,  0.2044],\n",
      "          [-0.3937, -0.3368, -0.1223]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8501,  0.4977,  0.8209],\n",
      "          [-0.1642, -0.0482, -0.2074],\n",
      "          [-0.8127, -0.4852, -0.4717]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4350,  0.5906, -0.2358],\n",
      "          [ 0.6677, -0.2312, -0.5057],\n",
      "          [ 0.0036, -0.4088, -0.2914]]],\n",
      "\n",
      "\n",
      "        [[[-0.2262,  0.1376,  0.2873],\n",
      "          [ 0.3484,  0.9641,  0.9536],\n",
      "          [ 0.4806,  0.9537,  0.9556]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3661,  0.3191, -0.3480],\n",
      "          [-0.2950, -0.1044,  0.0255],\n",
      "          [-0.2242, -0.2711,  0.1878]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0548,  0.2241,  0.3392],\n",
      "          [-0.4242,  0.1320,  0.2449],\n",
      "          [-0.6496, -0.2265,  0.6873]]]], device='cuda:0', requires_grad=True)), ('bias', Parameter containing:\n",
      "tensor([ 0.3525,  0.1758, -0.1078,  0.5580, -0.1937,  0.0264], device='cuda:0',\n",
      "       requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "checkpoint = exp.load_model(\"qmnist1\")\n",
    "exp.build_model(\"LeNet\") # Change this when going between different model architectures. \n",
    "exp.to_device()\n",
    "exp.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "exp.optim.load_state_dict(checkpoint['optim_state_dict'])\n",
    "print(list(exp.model.conv1.named_parameters())) # List weights of first layer in LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31afe80",
   "metadata": {},
   "source": [
    "Load a pruned/finetuned model.\n",
    "\n",
    "This is specific for qmnist, but the naming scheme is the same for the other models<br>\n",
    "example file: qmnist3.c30.pt <br>\n",
    "'qmnist' is the dataset the model is for<br>\n",
    "'3' is the model number (0-9)<br>\n",
    "c is whether it is after pruning or after finetuning. c for pruning and f for finetuning. <br>\n",
    "30 is what the compression ratio is. Can be 4, 10, 20, 30, 40, 50 for the CIFAR ones, or 4, 10, 20, 30, 40, 50 for <br>\n",
    "the QMNIST/Fashion ones <br>\n",
    "When passing the name to the load_model() function, do not include the .pt at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a58afa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mGPU AVAILABLE\n",
      "\u001b[0m\u001b[92mModel Pruned using GlobalMagWeight strategy\n",
      "\u001b[0m\u001b[92mGPU AVAILABLE\n",
      "\u001b[0m[('weight', Parameter containing:\n",
      "tensor([[[[-0.4261, -0.3670, -0.3651],\n",
      "          [ 0.0000,  0.0000,  0.1755],\n",
      "          [-0.4350, -0.3564, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1285,  0.8205,  1.1275],\n",
      "          [-0.0000, -0.0000, -0.0000],\n",
      "          [-1.0843, -0.8787, -0.7332]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6368,  0.7240, -0.3085],\n",
      "          [ 0.8393, -0.3091, -0.6965],\n",
      "          [ 0.0000, -0.5965, -0.3884]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.1981,  0.4300],\n",
      "          [ 0.5450,  1.1346,  1.2012],\n",
      "          [ 0.7503,  1.2435,  1.3005]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4447,  0.3670, -0.3518],\n",
      "          [-0.3388, -0.0000,  0.0000],\n",
      "          [-0.2564, -0.2722,  0.2224]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.4361,  0.4987],\n",
      "          [-0.6122,  0.1791,  0.5199],\n",
      "          [-0.9072, -0.3447,  0.9279]]]], device='cuda:0', requires_grad=True)), ('bias', Parameter containing:\n",
      "tensor([0.4347, 0.0000, 0.0000, 0.8149, -0.0000, 0.0000], device='cuda:0',\n",
      "       requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "checkpoint = exp.load_model(\"qmnist3.c30\")\n",
    "exp.build_model(\"LeNet\") # Change this when going between different model architectures.\n",
    "exp.to_device()\n",
    "\n",
    "exp.compression = 30\n",
    "exp.strategy = \"GlobalMagWeight\"\n",
    "exp.prune()\n",
    "exp.to_device()\n",
    "exp.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "exp.optim.load_state_dict(checkpoint['optim_state_dict'])\n",
    "print(list(exp.model.conv1.named_parameters())) # List weights of first layer in LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7e9075-2b33-4b90-aee7-39987f71a09b",
   "metadata": {},
   "source": [
    "`name_parameters()` returns weights at 0 and biases at 1. Here we only need weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c6a9c2-a518-4744-9ac6-40ec3a6526ff",
   "metadata": {},
   "source": [
    "Output shape formula\n",
    "```\n",
    "[(W−K+2P)/S]+1.\n",
    "```\n",
    "* W is the input volume - in your case 128\n",
    "* K is the Kernel size - in your case 5\n",
    "* P is the padding - in your case 0 i believe\n",
    "* S is the stride - which you have not provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6864d265-cb3b-40c7-ad4c-937d60c1f7ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### For calculate each layer\n",
    "This method contains two parameters:\n",
    "* Weights contains all the wights for all nodes at current layer, e.g. \n",
    "```python\n",
    "[[1,0,2,1],\n",
    " [1,1,0,0]]\n",
    "```\n",
    "* Previous path contains the number of path to previous layer of all nodes, e.g. \n",
    "```python\n",
    "[[1,5,2,8]]\n",
    "```\n",
    "\n",
    "The output for the example above would be `[11, 6]`, which is the number of paths for the input of the next layer.\n",
    "\n",
    "Note that the calculation start from the second layer, the path to the first layer is initialized to ones'array with the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0236bf98-702c-4c87-9968-cf85d1c36790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_linear_layer_paths(prev_paths, weights, threshold=None):\n",
    "    next_path = torch.tile(prev_paths, (weights.size()[0],)).reshape(weights.size())\n",
    "    if threshold == None:\n",
    "        next_path[weights == 0] = 0\n",
    "    else:\n",
    "        next_path[weights.abs() <= threshold] = 0\n",
    "    next_path = next_path.sum(axis=-1)\n",
    "    return next_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
